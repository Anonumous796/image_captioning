{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e195f1d3-c2f1-40eb-b163-3f6f736d615a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219417c6-bf1b-4ac2-a12d-474acb1fb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "!git clone https: // huggingface.co/facebook/nllb-200-distilled-600M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527164f-5caa-4455-b979-8d53512fb08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"SirNeural/flan_v2\", cache_dir=\"flan_v2\", data_files=\"cot_*_train.jsonl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c9b55-7f31-4c98-889e-5dac71b5ea24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", use_auth_token=True, src_lang=\"eng_Latn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", use_auth_token=True)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e9b2d-bf93-4fc7-b66c-b4494aed5ed9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "article = \"Hi cutie\"\n",
    "inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "\n",
    "translated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"rus_Cyrl\"], max_length=30)\n",
    "tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a46ae-e0e4-4f54-be30-4f5b982aaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2d93e-07ac-4038-a308-607d1e32b6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c05657-2b3e-45ae-ab3a-81485a87286a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "tasks = []\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    t = train_dataset[i]['inputs'].find(':')\n",
    "    if train_dataset[i]['inputs'][:t] not in tasks:\n",
    "        tasks.append(train_dataset[i]['inputs'][:t])\n",
    "tasks[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebbc0c-1891-4502-b74d-6ca6e79d2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    sentences.append(train_dataset[i]['inputs'])\n",
    "    sentences.append(train_dataset[i]['targets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c95a2e-abe4-486c-8d0a-356d318d2125",
   "metadata": {},
   "source": [
    "# Запуск перевода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d029690-2437-44d3-a59d-c40bbc9e1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from tqdm.auto import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "def predict(\n",
    "        model_name,\n",
    "        data_,\n",
    "        max_source_tokens_count=520,\n",
    "        max_target_tokens_count=520,\n",
    "        use_cuda=True,\n",
    "        batch_size=128\n",
    "):\n",
    "    russian_samples = []\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True, src_lang=\"eng_Latn\")\n",
    "    device = torch.device(\"cuda:1\") if use_cuda else torch.device(\"cpu\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, use_auth_token=True).to(device)\n",
    "    model.eval()\n",
    "    with autocast(dtype=torch.float16):\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "                batch = sentences[i:i + batch_size]\n",
    "                input_ids = tokenizer.prepare_seq2seq_batch(\n",
    "                    batch,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=max_source_tokens_count\n",
    "                )[\"input_ids\"].to(device)\n",
    "\n",
    "                output_ids = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    max_length=max_target_tokens_count,\n",
    "                    forced_bos_token_id=tokenizer.lang_code_to_id[\"rus_Cyrl\"]\n",
    "                )\n",
    "                decoded_output = tokenizer.batch_decode(output_ids, skip_special_tokens=True,\n",
    "                                                        clean_up_tokenization_spaces=False)\n",
    "\n",
    "                russian_samples.extend(decoded_output)\n",
    "\n",
    "                if (i // batch_size) % 10 == 0:\n",
    "                    with jsonlines.open('flan_traslation_v2.jsonl', mode='w') as writer:\n",
    "                        writer.write(russian_samples)\n",
    "    return russian_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59dc1e-4a61-458a-9474-722bba67e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "russian_samples = predict(\"facebook/nllb-200-distilled-600M\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e5040-4215-4d9e-8e1c-73a746b69e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with jsonlines.open('flan_traslation_v2.jsonl', mode='w') as writer:\n",
    "    writer.write(russian_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af456c8-f8e8-47b1-a9e5-0e26de3050ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('flan_traslation_v2.jsonl') as reader:\n",
    "    f = reader.read()\n",
    "f[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73373e28-60fe-47cb-ab46-c21068ee382d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ds = []\n",
    "t = {}\n",
    "for i in tqdm(range(0, len(f), 2)):\n",
    "    t = {'inputs': f[i], 'target': f[i + 1]}\n",
    "    ds.append(t)\n",
    "ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d15ac5-7766-421b-9d2a-f438cc500de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('flan_traslation_v22.jsonl', mode='w') as writer:\n",
    "    writer.write(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71854e-d593-4f85-a09b-0f8db1fd89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('flan_traslation_v22.jsonl', 'w') as f:\n",
    "    for item in ds:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641e600-a75c-40a6-bc56-b924f4609901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_reader(file_name):\n",
    "    with open(file_name, \"r\") as file:\n",
    "        reader = jsonlines.Reader(file)\n",
    "        for line in reader.iter():\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98ecb3-16db-4626-8c9f-02fc2732e7f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jsonl_reader('flan_traslation_v22.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project spring",
   "language": "python",
   "name": "project_spring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
