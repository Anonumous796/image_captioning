{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e219f51-d51f-49f1-bc05-d1a880a4ee85",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d767798-5660-43f8-8b29-2c96c94a5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import jsonlines\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.amp import autocast\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559f853-5a35-4e0e-8a51-5ba3e4926666",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb754941-d26e-4948-b125-dd8bae31a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_reader(file_name):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    with open(\"./data/\" + file_name, \"r\") as file:\n",
    "        reader = jsonlines.Reader(file)\n",
    "        for line in reader.iter():\n",
    "            inputs.append(line[\"inputs\"])\n",
    "            targets.append(line[\"target\"])\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89057d4c-a126-4eb1-864f-e332920c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlanDataset(Dataset):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenized = []\n",
    "\n",
    "        inputs, targets = jsonl_reader(\"flan_traslation_v22.jsonl\")\n",
    "\n",
    "        for inp, ans in tzip(inputs, targets):\n",
    "            pr = f\"{inp}, {ans}, {tokenizer.eos_token}\"\n",
    "            enc = self._encode(text=pr, tokenizer=tokenizer)\n",
    "            self.tokenized += [enc]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.tokenized[item]\n",
    "\n",
    "    def _encode(self, text, tokenizer):\n",
    "        encoded_sample = tokenizer.encode(text, padding='max_length', max_length=1024, truncation=True,\n",
    "                                          return_tensors='pt')\n",
    "        return encoded_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d38275-2f46-4117-a204-39da89af8ec1",
   "metadata": {},
   "source": [
    "# Готовим всё вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6468f6-39d1-43c6-8dd3-eebf7f4cadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('AlexWortega/wortegaLM-1b', padding_side='right')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('AlexWortega/wortegaLM-1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8755035-9c68-4311-a330-5d47431b0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb850b-652f-4ab5-a5f5-d9eb81003122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flan_dataset = FlanDataset(tokenizer)\n",
    "flan_dataset = torch.utils.data.ConcatDataset([flan_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba024f-98de-42d1-91ed-2239925751e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flan_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557472a-00d6-4922-a087-b6bd1ec2ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(flan_dataset, shuffle=True, batch_size=16, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859887c-7b80-4768-9cc2-982a95a3df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0fc97-cdea-40e2-8f51-edf818f93257",
   "metadata": {},
   "source": [
    "# Учим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd492b6-5706-41f8-acd1-a843897bd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA(nn.Module):\n",
    "    def __init__(self, decay):\n",
    "        super(EMA, self).__init__()\n",
    "        self.decay = decay\n",
    "        self.shadow_params = {}\n",
    "\n",
    "    def forward(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if name not in self.shadow_params:\n",
    "                    self.shadow_params[name] = param.data.clone()\n",
    "                else:\n",
    "                    self.shadow_params[name] -= (1 - self.decay) * (self.shadow_params[name] - param.data)\n",
    "                param.data = self.shadow_params[name]\n",
    "\n",
    "\n",
    "ema = EMA(decay=0.992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd48224-bd74-48e5-abdd-00353290c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=100, num_training_steps=len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257aa69c-78cf-426a-b4d2-412424245512",
   "metadata": {},
   "source": [
    "# Запускаемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea14729-9321-4afc-a068-1daba7a43fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=\"KEY\", relogin=True)\n",
    "wandb.init(sync_tensorboard=True, name='NAME', project=\"PROJECT\", entity=\"ENTITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d45b9f-d49d-47c3-8085-12cf53099b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db6a14-3f9d-4b40-ab96-9c90647ad39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(model, train_dataloader, epoch):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = batch.view(batch.shape[0], batch.shape[-1])\n",
    "\n",
    "        t = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            loss = model(input_ids=t, labels=t)['loss']\n",
    "            wandb.log({\"loss\": loss})\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema(model)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.save_pretrained(f'lm_saves/lm_{epoch}epoch')\n",
    "\n",
    "        del t\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d0c93-c3be-4756-ab79-2029ed7b8f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "    one_epoch(model, train_loader, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project spring",
   "language": "python",
   "name": "project_spring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
