{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9b5ab-08c2-4de8-87e5-d82d6eaaf3fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchmetrics.multimodal import CLIPScore\n",
    "\n",
    "metric = CLIPScore(model_name_or_path=\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7421b742-8a8c-4fbb-a3b8-cbd2eac30c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "\n",
    "\n",
    "def read_image(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "\n",
    "    resize = transforms.Resize([224, 224])\n",
    "    img = resize(img)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    tensor = to_tensor(img)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def show_image(path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    size = 400, 400\n",
    "    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image.thumbnail(size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc6986-f9e3-4f1d-8a74-3d5579a58e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"clipscore_test/1.jpg\"\n",
    "text = \"Хлеб розетка вселенная\"\n",
    "show_image(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f34506-e850-4c05-89d3-3f6707918fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoScore = metric(read_image(name), text)\n",
    "cocoScore.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619d492-7d24-4860-a9f8-16a9d78ab73a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multilingual_clip import pt_multilingual_clip\n",
    "import transformers\n",
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "\n",
    "model_name = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n",
    "\n",
    "model_caption = pt_multilingual_clip.MultilingualCLIP.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_img, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16-plus-240', pretrained=\"laion400m_e32\")\n",
    "model_img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67ce06-de34-48d0-99ac-c67674e9406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(logit_scale, img_embs, txt_embs):\n",
    "    # normalized features\n",
    "    image_features = img_embs / img_embs.norm(dim=-1, keepdim=True)\n",
    "    text_features = txt_embs / txt_embs.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # cosine similarity as logits\n",
    "    logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "    logits_per_text = logit_scale * text_features @ image_features.t()\n",
    "\n",
    "    # shape = [global_batch_size, global_batch_size]\n",
    "    return logits_per_image, logits_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dda0b-6dcb-417e-abd0-59ae137b7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_scale = model_img.logit_scale.exp().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa8cf9-c28c-4cfb-88aa-f40a45ce6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_logits(text, name):\n",
    "    text_features = model_caption.forward(text, tokenizer).detach().cpu()\n",
    "    with Image.open(name) as curimg:\n",
    "        images = preprocess(curimg).unsqueeze(0)\n",
    "    image_features = model_img.encode_image(images.to(device)).detach().float()\n",
    "    img_logits, text_logits = compare_embeddings(logit_scale, image_features, text_features.to(device))\n",
    "    return img_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e148205-0307-478f-a1d3-375a2e73a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = \"clipscore_test/2.jpg\"\n",
    "show_image(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724d562-19ef-4456-9cc6-ca9caaa28767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#«»\n",
    "text1 = \"Театр в городе Нижний Новгород\"\n",
    "give_logits(text1, name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd0776-b710-49aa-bf7f-aab3c49621b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name2 = \"clipscore_test/3.jpg\"\n",
    "show_image(name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cb04e-0628-4898-905f-8e878639a1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text2 = \"Александр Сергеевич Пушкин\"\n",
    "give_logits(text2, name2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project spring",
   "language": "python",
   "name": "project_spring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
