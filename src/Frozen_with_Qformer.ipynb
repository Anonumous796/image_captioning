{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ff570b-65b3-4112-b4b6-c4e5d5a193a2",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a4cdb7-482c-4228-936a-e2d212c63022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 13:12:33.244785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "import math\n",
    "from einops import rearrange\n",
    "from torch import einsum\n",
    "from torch.optim import AdamW\n",
    "import random\n",
    "\n",
    "from torch.nn import functional as nnf\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertLMHeadModel, Blip2QFormerModel\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import wandb\n",
    "import sys\n",
    "import cv2\n",
    "import torchvision.datasets as dset\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from typing import Tuple, Optional, Union, Any\n",
    "from torch.cuda.amp import autocast\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open_clip\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics import BLEUScore\n",
    "from evaluate import load\n",
    "from statistics import mean\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4686dab6-0a69-4fb4-9d7b-40d40c727c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dcbae-96d1-4c79-a35a-10ef7e891a33",
   "metadata": {},
   "source": [
    "# Конфиг модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59318ddd-6e94-4de6-abdc-559952b4c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "meteor = load('meteor')\n",
    "rouge = load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1d7182-5d05-4690-8506-014ac26e1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    encoder: str = \"ViT-B-16-plus-240\"\n",
    "    decoder: str = \"ai-forever/rugpt3medium_based_on_gpt2\"\n",
    "    batch_size: int = 24\n",
    "    num_epochs: int = 100\n",
    "    frozen_gpt: int = 20\n",
    "    frozen_clip: int = 60\n",
    "    learning_rate: float = 2e-4\n",
    "    save_path: str = \"model_saves/\"\n",
    "    prefix_length: int = 20\n",
    "    only_prefix: int = False\n",
    "    prefix: str = \"prefix_small\"\n",
    "    device: str = \"cuda:0\"\n",
    "    save_every: int = 1\n",
    "    warmup_steps: int = 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37430cf-beb6-4ea2-b0ce-6d80be952503",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Грузим данные|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.datasets.CocoDataset import CocoDataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a70d9d-e0ba-46c5-82f3-48e0b4e44c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CocoDataset(coef_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451b499-bd72-439d-94ff-bfc1ec4b050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = CocoDataset(image_path=\"data/coco_dataset/val2014\",\n",
    "                          ann_path=\"data/coco_dataset/annotations/captions_val2014.json\",\n",
    "                          caption_path=\"data/coco_dataset/coco_val_translation.jsonl\", data_type='val', coef_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e76fb5-2d45-4358-8fef-944d682d268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.show_image(random.randint(0, len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3878ca-df38-4e9e-b0d2-24bbcb81b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show_image(random.randint(0, len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5e723-1908-4907-ae33-fecd6bc1824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset[0][2]), len(train_dataset[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4ef7-41b7-4e59-86ce-5c9cca14a5ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Qformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16d9c0cc-d6b7-4f72-8e6e-5583cc1f0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.Model import ClipCaptionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02aeb3-5a28-4ef9-8a42-26b3f0785d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обучаемся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080883bc-4d67-40e2-a3ac-ce82adb6206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(relogin=True, key=\"\")\n",
    "wandb.init(project=\"\", sync_tensorboard=True, name=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5806d66d-7ecb-467b-848c-1f446713d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_sentences(sentences):\n",
    "    truncated_sentences = []\n",
    "    exclude = set(string.punctuation)\n",
    "    for sentence in sentences:\n",
    "        truncated_sentence = sentence\n",
    "        index = truncated_sentence.find(\"<pad>\")\n",
    "        if index != -1:\n",
    "            truncated_sentence = truncated_sentence[:index]\n",
    "        truncated_sentence = ''.join(ch for ch in truncated_sentence if ch not in exclude)\n",
    "        index = truncated_sentence.find(\"бродить\")\n",
    "        if index != -1:\n",
    "            truncated_sentence = truncated_sentence[index + 8:]\n",
    "        truncated_sentences.append(truncated_sentence)\n",
    "    return truncated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5812687-d711-4107-8ab6-76d2fd62fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_scorers = [BLEUScore(n_gram=i) for i in [1, 2, 3]] + [bertscore, meteor, rouge]\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, loss_func, loader, epoch, args):\n",
    "    model.train()\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    step = 0\n",
    "    for (query_tokens, query_mask, answer_tokens, answer_mask, prefix, idx) in pbar:\n",
    "\n",
    "        query_tokens, query_mask, prefix = query_tokens.to(args.device), query_mask.to(args.device), prefix.to(\n",
    "            args.device, dtype=torch.bfloat16)\n",
    "        answer_tokens, answer_mask = answer_tokens.to(args.device), answer_mask.to(args.device)\n",
    "        outputs, proj = model(query_tokens, query_mask, answer_tokens, answer_mask, prefix)\n",
    "        logits = outputs.logits\n",
    "        loss = nnf.cross_entropy(logits.reshape(-1, logits.shape[-1]), answer_tokens.flatten().to(torch.int64),\n",
    "                                 ignore_index=0)\n",
    "\n",
    "        loss2 = model.dist_loss(model.gpt.transformer.wte(answer_tokens).to(torch.float32), proj.to(torch.float32))\n",
    "        loss += loss2\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        pbar.set_postfix({\"loss\": loss.item(), \"dist_loss\": loss2.item()})\n",
    "        wandb.log({\"loss\": loss.item(), \"dist_loss\": loss2.item()})\n",
    "        step += 1\n",
    "        if step % 1000 == 0:\n",
    "            print(\"TEXT:\", train_dataset.tokenizer.decode(answer_tokens[0]))\n",
    "            print(\"PREDICTED: \", model.generate(torch.tensor([train_dataset[idx[0]][4].tolist()]).to(args.device),\n",
    "                                                [\"Что изображено на данной картинке?\"])[0])\n",
    "    with open(f'{args.save_path}checkpoint_{epoch}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, optimizer, scheduler, loss_func, loader, args):\n",
    "    model.eval()\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    step = 0\n",
    "\n",
    "    bl1 = []\n",
    "    bl2 = []\n",
    "    bl3 = []\n",
    "    brt = []\n",
    "    mtr = []\n",
    "    rg = []\n",
    "    val_losses = []\n",
    "    val_dist = []\n",
    "    for (query_tokens, query_mask, answer_tokens, answer_mask, prefix, idx) in pbar:\n",
    "        query_tokens, query_mask, prefix = query_tokens.to(args.device), query_mask.to(args.device), prefix.to(\n",
    "            args.device, dtype=torch.bfloat16)\n",
    "        answer_tokens, answer_mask = answer_tokens.to(args.device), answer_mask.to(args.device)\n",
    "        outputs, proj = model(query_tokens, query_mask, answer_tokens, answer_mask, prefix)\n",
    "        logits = outputs.logits\n",
    "        loss = nnf.cross_entropy(logits.reshape(-1, logits.shape[-1]), answer_tokens.flatten().to(torch.int64),\n",
    "                                 ignore_index=0)\n",
    "        loss2 = model.dist_loss(model.gpt.transformer.wte(answer_tokens), proj)\n",
    "\n",
    "        real = model.tokenizer.batch_decode(answer_tokens)\n",
    "        pred = model.generate(torch.tensor([val_dataset[idx[j]][4].tolist() for j in range(len(idx))]).to(args.device),\n",
    "                              [\"Что изображено на данной картинке? \" for _ in range(len(idx))])\n",
    "\n",
    "        real = truncate_sentences(real)\n",
    "        pred = truncate_sentences(pred)\n",
    "\n",
    "        #print(real, pred)\n",
    "        bl1.append(bleu_scorers[0](pred, real))\n",
    "        bl2.append(bleu_scorers[1](pred, real))\n",
    "        bl3.append(bleu_scorers[2](pred, real))\n",
    "        brt.append(bleu_scorers[3].compute(predictions=pred, references=real, lang=\"ru\")['f1'])\n",
    "        mtr.append(bleu_scorers[4].compute(predictions=pred, references=real)['meteor'])\n",
    "        rg.append(bleu_scorers[5].compute(predictions=pred, references=real)['rougeL'])\n",
    "\n",
    "        if step % 400 == 0:\n",
    "            print(\"TEXT:\", real[0])\n",
    "            print(\"PREDICTED: \", pred[0])\n",
    "\n",
    "            imgs = []\n",
    "            for j in range(len(idx)):\n",
    "                wa_img = wandb.Image(\n",
    "                    val_dataset.get_image(idx[j]),\n",
    "                    caption=f\"REAL : {real[j]}, PREDICTED : {pred[j]}\"\n",
    "                )\n",
    "                imgs.append(wa_img)\n",
    "\n",
    "            wandb.log({\"Generations.\": imgs})\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        pbar.set_postfix({\"val_loss\": loss.item(), \"val_dist\": loss2.item()})\n",
    "        val_losses.append(loss.item())\n",
    "        val_dist.append(loss2.item())\n",
    "\n",
    "    wandb.log({\"val_loss\": mean(val_losses),\n",
    "               \"val_dist\": mean(val_dist)})\n",
    "\n",
    "    wandb.log({\n",
    "        \"blue_1\": mean([tensor.item() for tensor in bl1]),\n",
    "        \"blue_2\": mean([tensor.item() for tensor in bl2]),\n",
    "        \"blue_3\": mean([tensor.item() for tensor in bl3]),\n",
    "        \"bert_score\": np.mean(np.mean([tensor for tensor in brt])),\n",
    "        \"meteor_score\": np.mean([tensor for tensor in mtr]),\n",
    "        \"rouge_score\": np.mean([tensor for tensor in rg])\n",
    "    })\n",
    "\n",
    "\n",
    "def fit_model(args=Config):\n",
    "    wandb.config = {\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"epochs\": args.num_epochs,\n",
    "        \"batch_size\": args.batch_size\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "    device = args.device\n",
    "\n",
    "    model = ClipCaptionModel(args.prefix_length)\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    wandb.watch(model, log_freq=10, log=\"gradients\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adafactor(model.parameters(), lr=args.learning_rate,\n",
    "                          relative_step=False  # for adafactor\n",
    "                          )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=20, shuffle=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=20, shuffle=True, drop_last=False)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer, T_max=15000\n",
    "    )\n",
    "    print(\"ZERO SHOT\")\n",
    "    evaluate(model, optimizer, scheduler, loss_func, val_loader, args)\n",
    "    print(\"Start train model\")\n",
    "    for epoch in range(args.num_epochs):\n",
    "        if epoch == args.frozen_gpt:\n",
    "            print(\"GPT UNFROZEN\")\n",
    "            for p in model.gpt.parameters():\n",
    "                p.requires_grad = True\n",
    "        if epoch == args.frozen_clip:\n",
    "            print(\"CLIP UNFROZEN\")\n",
    "            for p in model.clip_model.parameters():\n",
    "                p.requires_grad = True\n",
    "        print(f\"---------- Train epoch {epoch} ---------\")\n",
    "        train(model, optimizer, scheduler, loss_func, train_loader, epoch, args)\n",
    "        print(f\"---------- Evaluate epoch {epoch} ---------\")\n",
    "        evaluate(model, optimizer, scheduler, loss_func, val_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6964e7-601c-4424-a0c4-4eaedcaf0d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZERO SHOT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad3d15ef6e74174ac085bb9a8017d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/418 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Есть слон который лежит в траве\n",
      "PREDICTED:  неправильно я от ты не злоупотреблениелите часто страдают при избыточный в результате изли\n",
      "TEXT: Три птицы стоят на влажной земле снаружи\n",
      "PREDICTED:  неправильно я от ты не злоупотреблениелите часто страдают при избыточный в результате изли\n",
      "Start train model\n",
      "---------- Train epoch 0 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490488fb42734d24bfab12ab797ea70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8442 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Оранжево-белая кошка лежит на кровати.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В этом случае, когда мы не можем быть уверены в том что это будет правильно и\n",
      "TEXT: Двое детей играют в ванне с пеной.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  Он не был в состоянии, чтобы сделать это и он сказал: \"Я хочу быть\n",
      "TEXT: Люди переходят улицу в пешеходном режиме перед ожидающим автобусом.<pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В это время на поле, где он играл в теннис с командой США по теннису\n",
      "TEXT: Две женщины посреди игры в теннис.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.\n",
      "- Я не могу, - сказал он и упал на колени.- Не может быть!\n",
      "TEXT: Трое лыжников стоят на вершине горного склона.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. \n",
      "- Я не могу, - сказал он и пошел к своему месту на доске для\n",
      "TEXT: Женщина просматривает холодильник с открытой дверцей.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. \n",
      "- Я не могу, - сказал он и пошел к машине.- Эй! Ты\n",
      "TEXT: Аккуратный современный туалет с туалетом в дальнем углу<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В ванной комнате: ванна, раковина с душем и унитаз (с\n",
      "TEXT: ванная комната с унитазом, раковиной и зеркалом<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В ванной комнате есть раковина, унитаз и душ с горячей водой (входит\n",
      "---------- Evaluate epoch 0 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be495d479c1a4528aa3faea139ddafcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/418 [00:07<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Показана кухня с разнообразными предметами на прилавках\n",
      "PREDICTED:   В ванной комнате ванна раковина с душем и унитазом сти\n",
      "TEXT: Маленький ребенок в куртке ест пончик\n",
      "PREDICTED:   Он не может понять что он делает и почему его рука лежит на столе с такой\n",
      "---------- Train epoch 1 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9adc9322dc44ee7b08d1c509d1b1930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8442 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Группа женщин общается в столовой.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  Он не был в состоянии сказать, что он видел ее раньше и она была с ним\n",
      "TEXT: Это похоже на какой-то футуристический душ со множеством гаджетов.<pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В ванной комнате ванна с душевой лейкой, раковиной и унитазом а\n",
      "TEXT: Реактивный самолет US Airways въехал во двор аэропорта.<pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.\n",
      "Внизу, в долине на высоте около 1000 метров над уровнем моря находится город-приз\n",
      "TEXT: Девушка в галстуке стоит у кирпичной стены<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  Он был в белой рубашке, и он держал ее на руках с правой стороны от себя\n",
      "TEXT: Мать и малыш Жирафы стоят в загоне.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. \n",
      "- Я не могу, - говорит он и уходит в сторону от них на несколько\n",
      "TEXT: Коробка, полная разнообразных пончиков<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  Вкусный, но не очень вкусный! \n",
      "\n",
      " \"Сделано в России\n",
      "TEXT: Большая сумка с ноутбуком внутри.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  Он был одет в белую рубашку с галстуком, и на нем были черные брюки-\n",
      "TEXT: Еда раскладывается на столе в тарелках.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  Вкусненькый и нежный салат с моцареллой, помидорами\n",
      "---------- Evaluate epoch 1 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0f9606ad53469d9a3a3becaabf89f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/418 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Это хотдог с помидорами горчицей луком приправой и маринов\n",
      "PREDICTED:   Вкусняшка \n",
      "\n",
      " Сделано в России  это журнал\n",
      "TEXT: Женщина кормит лошадь на ранчо\n",
      "PREDICTED:   Эй эй  кричит он в ответ на крик девушки и тут же падает\n",
      "GPT UNFROZEN\n",
      "---------- Train epoch 2 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db80bbe638741f29bea593b8ef83d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8442 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Два ягненка стоят на травянистом холме.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В то время как он держит в руках, а другой человек катается на доске по\n",
      "TEXT: Человек на сноуборде выполняет воздушный трюк.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.Снегоуборщик, который катается на лыжах по склону в небе с горы и\n",
      "TEXT: Ингредиенты для шоколадного десерта сидят на прилавке.<pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.  В тарелке лежит кусок мяса, на котором лежат овощи и рядом с ним тарелка со\n",
      "TEXT: На базе стоит человек с битой.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.\n",
      "больный бейсболист, который держит мяч в воздухе на поле для игры с мячом\n",
      "TEXT: Многие люди ходят по улице с зонтами в руках.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. на заднем плане, в поле стоит сенок и пасутся коровы по полю рядомя к\n",
      "TEXT: Один жираф стоит за мертвой веткой дерева.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить, в. на и с а з за к по-к у стоит друг другу людито\n",
      "TEXT: Пара теннисистов тренируется перед матчем.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить.течу на кортах, мя стоит в теннисном поле с ракеткой и мяч летит\n",
      "TEXT: Боковое зеркало скутера с отражением магазинов магазинов<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. на улице, а рядом с ним и припарковом в зданиями-каффан по\n",
      "---------- Evaluate epoch 2 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426882a1bcbe4e0285dfcf800613d49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/418 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Маленькая девочка бросает фрисби с женщиной\n",
      "PREDICTED:  ольный чтобы на поле в мяччу мя сольного и битуном кой\n",
      "TEXT: Тарелка стейка кукурузы и брокколи на пару\n",
      "PREDICTED:  тарелке и с на столе а также брокколи фриойкой в нейом овощами\n",
      "GPT UNFROZEN\n",
      "---------- Train epoch 3 ---------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a895830fbe5448d8a0c1284a633468ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8442 [00:06<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: Парад лошадей пересекает пустую дорогу<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. на улице, с припарков в и рядомом по обочине дороге перед зданием зданиями города-\n",
      "TEXT: Женщина-лыжница делает поворот на вершине горы.<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "PREDICTED:   бродить. на лыжах, в ске и по снегуорде горыки-на склоне холмается\n"
     ]
    }
   ],
   "source": [
    "fit_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project spring",
   "language": "python",
   "name": "project_spring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
